{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "668803a9-def9-40ea-90c6-13c48aa0e855",
   "metadata": {},
   "source": [
    "## Required Libraries\n",
    "\n",
    "The following libraries are already available in this lab environment:\n",
    "\n",
    "- **pandas** → for creating and displaying comparison tables\n",
    "- **numpy** → for handling numerical calculations\n",
    "- **time** → for measuring latency\n",
    "- **agent framework (pre‑installed)** → provides the functions `run_react_agent()` and `run_reflexion_agent()`\n",
    "\n",
    "You do **not** need to install anything manually. Just run the cells in order.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2294e403-2b9f-474b-985e-a6c010128ea9",
   "metadata": {},
   "source": [
    "## How to Run Cells\n",
    "\n",
    "- Select a code cell by clicking on it.\n",
    "- Press **Shift + Enter** or click the **Run** button in the toolbar.\n",
    "- The output will appear directly below the cell.\n",
    "\n",
    "We will start with **Part 1: ReAct Agent Benchmark**, then move to **Part 2: Reflexion Agent Benchmark**, and finally complete **Part 3: Analysis & Recommendation**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55dd70c3-f895-47c5-9805-7ae668ad55b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "import pandas as pd\n",
    "def run_react_agent():\n",
    "    \"\"\"\n",
    "    Simulated ReAct agent benchmark.\n",
    "    Returns success rate and average latency in ms.\n",
    "    \"\"\"\n",
    "    # Simulate processing\n",
    "    time.sleep(1)\n",
    "    success_rate = 0.80   # 80% success\n",
    "    avg_latency_ms = 1200 # 1.2 seconds\n",
    "    return {\"success_rate\": success_rate, \"avg_latency_ms\": avg_latency_ms}\n",
    "    \n",
    "def run_reflexion_agent():\n",
    "    \"\"\"\n",
    "    Simulated Reflexion agent benchmark.\n",
    "    Returns success rate and average latency in ms.\n",
    "    \"\"\"\n",
    "    # Simulate slower processing\n",
    "    time.sleep(3)\n",
    "    success_rate = 1.00   # 100% success\n",
    "    avg_latency_ms = 3500 # 3.5 seconds\n",
    "    return {\"success_rate\": success_rate, \"avg_latency_ms\": avg_latency_ms}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d979dd34-bd65-42e7-94f9-d67b98148c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part 1: ReAct Agent Benchmark\n",
    "\n",
    "react_results = run_react_agent()\n",
    "\n",
    "print(\"ReAct Agent Results\")\n",
    "print(\"Success Rate:\", react_results[\"success_rate\"])\n",
    "print(\"Average Latency (ms):\", react_results[\"avg_latency_ms\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc16c0c-f5f7-48e5-b34f-ab59edaadaa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part 2: Reflexion Agent Benchmark\n",
    "\n",
    "reflexion_results = run_reflexion_agent()\n",
    "\n",
    "print(\"Reflexion Agent Results\")\n",
    "print(\"Success Rate:\", reflexion_results[\"success_rate\"])\n",
    "print(\"Average Latency (ms):\", reflexion_results[\"avg_latency_ms\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070fc6a2-5f35-47f8-aee3-fa5e2e1a1639",
   "metadata": {},
   "source": [
    "# Part 3: Analysis & Recommendation\n",
    "\n",
    "Now that we have our data, what do we do with it? We analyze it.\n",
    "\n",
    "In this section, your job is to:\n",
    "- Fill in the table below with the four metrics you generated (success rate and average latency for each agent).\n",
    "- Write one sentence summarizing the trade‑offs.\n",
    "- Write a short recommendation justifying which agent you would choose for the travel‑planning scenario and why.\n",
    "\n",
    "\n",
    "## Comparison Table\n",
    "\n",
    "| Agent      | Success Rate | Avg Latency (ms) |\n",
    "|------------|--------------|------------------|\n",
    "| ReAct      |              |                  |\n",
    "| Reflexion  |              |                  |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5a96a9-8f5b-47eb-832d-e6ee739578da",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "\n",
    "Summarize the trade‑offs between ReAct and Reflexion based on the metrics above.  \n",
    "*(Example: ReAct is faster but less reliable, while Reflexion is more reliable but slower.)*\n",
    "\n",
    "## Recommendation\n",
    "\n",
    "Write one or two sentences recommending which agent you would choose for the travel‑planning scenario, and explain why.  \n",
    "*(Example: For a travel planner, reliability is more important than speed, so Reflexion is the better choice.)*\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
